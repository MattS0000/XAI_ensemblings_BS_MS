{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd980d-950d-4a8b-bdfa-83aa7e599bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import copy\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "from os import path\n",
    "from skimage import io\n",
    "from torch import optim\n",
    "from torch.nn import Linear, CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd6197-4964-4285-b64c-e12ad7149086",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_frame = pd.read_csv(path.join('..', 'input', 'inz-data-prep', 'easy_labels_and_data.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae8a424-783a-4589-b80b-0393e84a980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_bbox(image, bboxes: pd.DataFrame):\n",
    "    plt.imshow(image)\n",
    "    ax = plt.gca()\n",
    "    for idx, bbox in bboxes.iterrows():\n",
    "        x = (bbox[0] - bbox[2] / 2) * 512\n",
    "        y = (bbox[1] - bbox[3] / 2) * 512\n",
    "\n",
    "        rect = Rectangle((x, y), bbox[2] * 512, bbox[3] * 512, fill=False, edgecolor='r')\n",
    "        ax.add_patch(rect)\n",
    "    \n",
    "plt.figure()\n",
    "show_image_bbox(io.imread(path.join('../input/crop-and-weed-detection-data-with-bounding-boxes/agri_data/data/agri_0_1009.jpeg')), \n",
    "               labels_frame.iloc[1343:, 2:6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c7f1da-262c-495e-95fe-019544d11353",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9768cb3-9d91-4537-b7ab-bf94874c6962",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropWeedDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, labels_csv, images_dir, transform=None):\n",
    "        self.labels_frame = pd.read_csv(labels_csv, index_col=0)\n",
    "        self.grouped_labels_frame = self.labels_frame.groupby('filename').count()\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.grouped_labels_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = path.join(self.images_dir,\n",
    "                                self.grouped_labels_frame.iloc[idx].name)\n",
    "        image = io.imread(img_name)\n",
    "        label = int(self.grouped_labels_frame.iloc[idx, 0] > 0)\n",
    "        \n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def get_bbox(self, idx):\n",
    "        bbox = self.labels_frame.loc[self.labels_frame['filename'] == self.grouped_labels_frame.iloc[idx].name].iloc[:,2:6]\n",
    "        return bbox\n",
    "    \n",
    "    def show_image(self, idx):\n",
    "        sample = self[idx]\n",
    "        bbox = self.get_bbox(idx)\n",
    "\n",
    "        if self.transform:\n",
    "            numpy_image = sample['image'].numpy().transpose(1, 2, 0)\n",
    "        else:\n",
    "            numpy_image = sample['image']\n",
    "\n",
    "        show_image_bbox(numpy_image, bbox)\n",
    "\n",
    "    \n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image) / 255,\n",
    "                'label': torch.asarray(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f66797-a4e0-4012-9725-be6efc916c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CropWeedDataset(labels_csv=path.join('..', 'input', 'inz-data-prep', 'easy_labels_and_data.csv'),\n",
    "                          images_dir=path.join('..','input','crop-and-weed-detection-data-with-bounding-boxes','agri_data', 'data'),\n",
    "                          transform=ToTensor())\n",
    "\n",
    "dataset.show_image(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de2568-390b-46b5-ba58-09aebbac6ba3",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b3d697-1ec2-4535-b5d0-74fa701bbae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = random_split(dataset, [950, 204], generator=torch.Generator().manual_seed(420))\n",
    "dataloaders = {'train':DataLoader(train, batch_size=8, shuffle=True, num_workers=2), \n",
    "               'val': DataLoader(test, batch_size=8, shuffle=True, num_workers=2)}\n",
    "dataset_sizes = {'train': 950,\n",
    "                'val': 204}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b29bdb-6fba-421d-9e9c-5257a05129a1",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a971b6-2e2d-4148-ab73-8808c79bb03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True) # shows warning, but new version (weights=models.ResNet18_Weights.IMAGENET1K_V1) doesn't work on kaggle\n",
    "model.fc = Linear(512, 2)\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35dfc90-c67e-4db4-abc4-89a3b4bdc5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=10):\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for batch in dataloaders[phase]:\n",
    "                inputs = batch['image'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a5cfce-2f30-4ffb-9457-336ea149e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3326c-82c5-4631-8eeb-0e73ffd912be",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), path.join('models', 'resnet-18'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
